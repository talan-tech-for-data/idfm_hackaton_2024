{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1817534a-aa76-48e6-a4bc-5c625676f5e1",
   "metadata": {},
   "source": [
    "<img src=\"images/logo_simple.png\" alt=\"logo\" width=\"400\"/>\n",
    "\n",
    "# Retrieval Augmented Generation - Indexation\n",
    "\n",
    "Nous vous proposons dans ce notebook un template alimentant notre base de données vectorielle (ici Elastic Search) fonctionnant sur la plateforme Onyxia et l'environement Azure disponible chez IDFM.\n",
    "\n",
    "## Langchain\n",
    "\n",
    "Ce template est basé sur [langchain](https://python.langchain.com/docs/introduction/), librairie devenue un standard dans l'utilisation des LLM en général.\n",
    "Le tutoriel de langchain disponible en suivant ce [lien](https://python.langchain.com/docs/tutorials/rag/)\n",
    "\n",
    "## Fonctionnement\n",
    "\n",
    "Un RAG est une technique permettant d'enrichir les connaissances des LLM avec des données supplémentaires.\n",
    "\n",
    "Les LLM peuvent raisonner sur des sujets très variés, mais leurs connaissances sont limitées aux données qui ont été utilisées pour leur entraînement. Si vous souhaitez créer des applications d'IA capables de traiter des données privées ou des données introduites après la date limite d'un modèle, vous devez enrichir les connaissances de celui-ci avec les informations spécifiques dont il a besoin. Le processus consistant à apporter les informations appropriées et à les insérer dans l'invite du modèle est connu sous le nom de \"Retrieval Augmented Generation\" (RAG).\n",
    "\n",
    "LangChain dispose d'un certain nombre de composants conçus pour faciliter la création d'applications de questions-réponses et, plus généralement, d'applications de RAG.\n",
    "\n",
    "Le fonctionnement standard d'un RAG fait intervenir deux étapes :\n",
    "  - **L'indexation :** Phase au cours de laquelle nous déposons et indexons notre corpus de documents dans la base de données utilisée.\n",
    "  - **Le retrieval & generation :** Phase qui nous permet d'executer le RAG et de l'appeler avec un prompt.\n",
    "\n",
    "Ici, nous allons voir la partie **Indexation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a903f5-0509-495a-90c2-2f904d1b2599",
   "metadata": {},
   "source": [
    "## Indexation\n",
    "\n",
    "L'indexation s'effectue en trois étapes :\n",
    "  - **Chargement des données :** Cette opération consiste simplement à charger des données depuis une source souhaité tel qu'internet, notre system de fichier local, une base de donnée privée... Nous utiliserons ici des données disponibles sur le system de fichier local du notebook. Sous langchain cet operation peut être effectuée à l'aide de [Document Loaders](https://python.langchain.com/docs/concepts/#document-loaders)\n",
    "  - **Diviser :** Les séparateurs de texte divisent les documents volumineux plusieurs petits documents. Cela est utile à la fois pour indexer les données et pour les transmettre à notre modèle qui dispose d'un nombre de token d'appel limité. Langchain propose pour cela des [Text splitters](https://python.langchain.com/docs/concepts/#text-splitters).\n",
    "  - **Stocker :** Le stockage et l'indexation se fait ensuite généralement sur des bases de données vectorielles à partir d'indexations faites à l'aide d'un modèle d'embeding. Langchain propose pour cela les objets [VectorStore](https://python.langchain.com/docs/concepts/#vector-stores) et [Embeddings model](https://python.langchain.com/docs/concepts/#embedding-models)\n",
    "\n",
    "<img src=\"images/rag_indexing.png\" alt=\"logo\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed434850-c073-4857-8258-368119b24dca",
   "metadata": {},
   "source": [
    "## Faire un bon embedding\n",
    "\n",
    "\n",
    "### Conservation du contexte\n",
    "\n",
    "- **Petits segments (chunk_size) :** Si vous segmentez un document en morceaux trop petits, chaque segment peut perdre une partie du contexte. Par exemple, diviser un paragraphe en phrases individuelles peut rendre difficile la capture de la signification globale.\n",
    "- **Grands segments (chunk_size) :** Si les segments sont trop grands, vous risquez de dépasser les limites du modèle ou d'incorporer trop d'informations non pertinentes, ce qui peut diluer l'embedding.\n",
    "\n",
    "\n",
    "### Types de documents et objectifs\n",
    "\n",
    "Le choix du *chunk_size* dépend aussi du type de document que vous traitez et de vos objectifs.\n",
    "\n",
    "- **Textes longs (articles, livres, etc.) :** Ici, il est souvent recommandé de segmenter par paragraphe ou bloc sémantiquement cohérent (comme une section). Cela permet de conserver du contexte tout en gardant chaque chunk suffisamment petit.\n",
    "\n",
    "- **Textes courts/Question-réponse ou recherche d'information :** Si vous prévoyez d'utiliser les embeddings pour rechercher des réponses précises, un chunk de taille moyenne, correspondant à un paragraphe ou quelques phrases (par exemple, 100-300 tokens), peut fournir un bon équilibre entre contexte et spécificité.\n",
    "\n",
    "\n",
    "### Techniques pour améliorer les embeddings avec des chunks\n",
    "\n",
    "- **Sliding window :** Utiliser une fenêtre glissante permet de créer des segments qui se chevauchent légèrement. Cela garantit que les phrases situées aux limites d'un chunk ne perdent pas leur contexte. Par exemple, si vous avez un chunk de 200 tokens, vous pouvez faire un chevauchement de 50 tokens avec le chunk suivant. Pour cela vous pouvez utiliser le paramètre *chunk_overlap*.\n",
    "\n",
    "- **Segmentation naturelle :** Diviser en plusieurs documents si vous voulez insérer des informations sur divers sujets dans votre index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e788f3db-4094-49f5-bee1-0a2337b7c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=Warning,\n",
    "    message=\".*ElasticVectorSearch.*|.* using TLS with verify_certs=False is insecure.*|.*Unverified HTTPS request.*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1716f705-0700-422b-b2e4-228d01b966e3",
   "metadata": {},
   "source": [
    "### Initialisation des identifiants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ffa8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "path_secrets = os.getcwd()+\"/secrets.env\"\n",
    "load_dotenv(dotenv_path=Path(path_secrets).resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19bd6c12",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AZURE_ENDPOINT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAZURE_ENDPOINT\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AZURE_ENDPOINT' is not defined"
     ]
    }
   ],
   "source": [
    "AZURE_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d64e12ce-3f25-42f0-92fb-1eb0b96ef117",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "API_VERSION = \"2024-09-01-preview\"\n",
    "AZURE_ENDPOINT = os.getenv('OPENAI_AZURE_ENDPOINT')\n",
    "API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "azure_open_ai_parameters = {\n",
    "    \"api_version\": API_VERSION,\n",
    "    \"azure_endpoint\": AZURE_ENDPOINT,\n",
    "    \"api_key\": API_KEY\n",
    "}\n",
    "\n",
    "elastic_search_parameters = {\n",
    "    \"username\": \"elastic\",\n",
    "    \"password\": os.getenv('ELASTICSEARCH_PASSWORD')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b27d7a-14e4-4c10-a23a-8f005287320e",
   "metadata": {},
   "source": [
    "### Création de notre model d'embeding\n",
    "\n",
    "Cet embedding est basé sur un model open AI hébergé sur la plateforme Azure d'IDFM appelé à l'aide d'une API.\n",
    "\n",
    "Ici, le modèle va permettre de générer différents vecteur pour les différents documents que l'on a avant de les stocker dans notre base de données vectorielle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4c91b02-fbc6-4b12-9a9c-05991a5ad52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embedding_model = AzureOpenAIEmbeddings(\n",
    "    **azure_open_ai_parameters,\n",
    "    model=\"hackathon-embedding\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a468d878-b9c6-42ec-bc94-bc8f3395992f",
   "metadata": {},
   "source": [
    "### Creation de notre Vector Store\n",
    "\n",
    "Ici un vector store sur Elastic Search. Vous pouvez regarder la base de données Elastic Search via Onyxia.\n",
    "Vous devez créer votre index personnel avant d'insérer vos documents (exemple: prénom_nom_index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f13edef-135f-4c19-b132-5ebcc6e84c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96213/1629589372.py:5: LangChainPendingDeprecationWarning: The class `ElasticVectorSearch` will be deprecated in a future version. Use :class:`~Use ElasticsearchStore class in langchain-elasticsearch package` instead.\n",
      "  vector_store = ElasticVectorSearch(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import ElasticVectorSearch\n",
    "\n",
    "index = \"test_referentiel\" \n",
    "\n",
    "vector_store = ElasticVectorSearch(\n",
    "    elasticsearch_url=f\"https://{elastic_search_parameters[\"username\"]}:{elastic_search_parameters[\"password\"]}@elastic-826951-elasticsearch:9200\",\n",
    "    index_name=index,\n",
    "    embedding=embedding_model,\n",
    "    ssl_verify = {'verify_certs': False}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2369b6c5-8cff-43de-8ead-a702bed98497",
   "metadata": {},
   "source": [
    "### Initialisation de notre Document loader et splitter\n",
    "\n",
    "Le document donné est un exemple, vous pouvez ajouter des documents dans le dossier data et changer le chemin ci-dessous vers votre document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a93b9a0-d379-4eee-8c5f-ba7777eb95be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.schema import Document\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# doc_path = \"./data/documentation_referentiel_arret.txt\"  # TODO: Ajouter un document dans data et modifier le chemin\n",
    "\n",
    "df = pd.read_parquet(\"referentiel-des-lignes.parquet\")\n",
    "df['content'] = df.apply(\n",
    "    lambda row: ', '.join([f\"{col}: {row[col]}\" for col in df.columns]), axis=1\n",
    ")\n",
    "\n",
    "# Convertir les lignes en documents\n",
    "documents = [\n",
    "    Document(page_content=row['content'], metadata={\"id\": row['id_line']})\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "splits = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a56b1ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'id': 'C00003'}, page_content='id_line: C00003, name_line: Licorne, shortname_line: Licorne, transportmode: bus, transportsubmode: localBus, type: None, operatorref: 1004, operatorname: Keolis Ouest Val-de-Marne, additionaloperators: None, networkname: Seine Grand Orly, colourweb_hexa: e2007a, textcolourweb_hexa: ffffff, colourprint_cmjn: 0 100 46 11, textcolourprint_hexa: ffffff, accessibility: false, audiblesigns_available: true, visualsigns_available: true, id_groupoflines: A02312, shortname_groupoflines: VILLENEUVE-LE-ROI (la Fresnaie) - VILLENEUVE-LE-ROI (foyer Jean Rostand), notice_title: None, notice_text: None, picto: None, valid_fromdate: 2014-07-16, valid_todate: None, status: active, privatecode: 522522481')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e949aba1-2026-402e-8e0a-79513e3ef8f7",
   "metadata": {},
   "source": [
    "### Indexation de documents\n",
    "\n",
    "Étape d'ajout des documents à notre base de donnée vectorielle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30696555-8c61-4769-bee0-33b4ae4d09d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m         doc_batch \u001b[38;5;241m=\u001b[39m splits[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m      4\u001b[0m         vector_store\u001b[38;5;241m.\u001b[39madd_documents(documents\u001b[38;5;241m=\u001b[39mdoc_batch)\n\u001b[0;32m----> 6\u001b[0m \u001b[43madd_documents_by_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m, in \u001b[0;36madd_documents_by_batch\u001b[0;34m(vector_store, splits, batch_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(splits), batch_size):\n\u001b[1;32m      3\u001b[0m     doc_batch \u001b[38;5;241m=\u001b[39m splits[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mvector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoc_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/.venv/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:287\u001b[0m, in \u001b[0;36mVectorStore.add_documents\u001b[0;34m(self, documents, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    286\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`add_documents` and `add_texts` has not been implemented \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "File \u001b[0;32m~/work/.venv/lib/python3.12/site-packages/langchain_community/vectorstores/elastic_vector_search.py:213\u001b[0m, in \u001b[0;36mElasticVectorSearch.add_texts\u001b[0;34m(self, texts, metadatas, ids, refresh_indices, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m requests \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    212\u001b[0m ids \u001b[38;5;241m=\u001b[39m ids \u001b[38;5;129;01mor\u001b[39;00m [\u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[0;32m--> 213\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(embeddings[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    215\u001b[0m mapping \u001b[38;5;241m=\u001b[39m _default_text_mapping(dim)\n",
      "File \u001b[0;32m~/work/.venv/lib/python3.12/site-packages/langchain_openai/embeddings/base.py:588\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[1;32m    587\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/.venv/lib/python3.12/site-packages/langchain_openai/embeddings/base.py:483\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    481\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[0;32m--> 483\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invocation_params\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    487\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[0;32m~/work/.venv/lib/python3.12/site-packages/openai/resources/embeddings.py:124\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    118\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    119\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/.venv/lib/python3.12/site-packages/openai/_base_client.py:1278\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1266\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1273\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1275\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1276\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1277\u001b[0m     )\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/work/.venv/lib/python3.12/site-packages/openai/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/.venv/lib/python3.12/site-packages/openai/_base_client.py:1059\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1056\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1058\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1059\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1062\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1063\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1067\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1068\u001b[0m )\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}"
     ]
    }
   ],
   "source": [
    "def add_documents_by_batch(vector_store, splits, batch_size=200):\n",
    "    for i in range(0, len(splits), batch_size):\n",
    "        doc_batch = splits[i:i + batch_size]\n",
    "        vector_store.add_documents(documents=doc_batch)\n",
    "\n",
    "add_documents_by_batch(vector_store, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860d3d41-3d20-4828-8e81-b9329fb2dfd6",
   "metadata": {},
   "source": [
    "### Elasticsearch\n",
    "\n",
    "Après avoir créé votre index, vous pouvez aller sur la page graphique d'Elasticsearch [ici](https://dlb-deptdata-826951.data-platform-self-service.net/app/enterprise_search/content/search_indices) pour voir les documents insérés dedans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6095e851-2f17-4034-afc2-f797f892fdbc",
   "metadata": {},
   "source": [
    "### ⚠️ Réinitialisation de la base de données ⚠️\n",
    "\n",
    "Si jamais vous avez ajouté plusiseurs fois les mêmes documents, ou si vous voulez tester de nouvelles choses, vous pouvez supprimer votre index à l'aide de ce code.\n",
    "\n",
    "**⚠️ Attention, ce code supprime l'index d'Elasticsearch !!! ⚠️**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9d9d43-473f-4bf7-bca5-4b5dd6cc88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch(\n",
    "    hosts=[f\"https://{elastic_search_parameters[\"username\"]}:{elastic_search_parameters[\"password\"]}@elastic-826951-elasticsearch:9200\"],\n",
    "    verify_certs=False\n",
    ")\n",
    "\n",
    "if es_client.indices.exists(index=index):\n",
    "    es_client.indices.delete(index=index)\n",
    "    print(f\"L'index '{index}' a été supprimé.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
